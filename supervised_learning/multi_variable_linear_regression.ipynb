{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b62a60f-840e-44c9-80b3-9d385329e695",
   "metadata": {},
   "source": [
    "## Multi Varaible Linear Regression\n",
    "\n",
    "In this notebook I cover the concept of `multivariable linear regression`. The difference between `multi variable linear regression` and `simple linear regresssion` is about the number of *independent* variables. In crast with `linear regresssion` the `multi variable linear regression` has more than one *independent* vairable. \n",
    "\n",
    "The $x$ data is a matrix of features. There are are $n$ features and $m$ training examples Each row of the matrix represents one example. When you have $m$ training examples. \n",
    "- $m$ == number of rows\n",
    "- $n$ == number of columns\n",
    "\n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "The data includes the house specification and the price. The features are *size*, *number of beds*, *age of home*, and the target values are *price*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efb949ed-8205-492c-ad4b-02e1be9d7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4fb457-1ccc-4f0d-93ed-341ed9932cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict ={\n",
    "    'size' : [200, 1000, 2000],\n",
    "    'number of beds': [1, 2, 4],\n",
    "    'age of home' : [30, 40, 50],\n",
    "    'price': [100, 230, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef5d025-0417-46bc-a4fc-34589111e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a174a985-8cc1-4380-8b82-5a9ee1cf23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>number of beds</th>\n",
       "      <th>age of home</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  number of beds  age of home  price\n",
       "0   200               1           30    100\n",
       "1  1000               2           40    230\n",
       "2  2000               4           50    500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46465cb-7133-4e20-953f-6c3a20e9a6e4",
   "metadata": {},
   "source": [
    "Since there are multiple features, there must be $n$ a vector of $w$ with $n$ elements. \n",
    "\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "but $b$ is a scalar value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef4c2b-f157-44ba-8213-444060e16d8a",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "The model has $n$ features thus a vector $w$. \n",
    "\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) =  w_0x_0 + w_1x_1 +... + w_{n-1}x_{n-1} + b \\tag{1}$$\n",
    "or in vector notation:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b  \\tag{2} $$ \n",
    "where $\\cdot$ is a vector `dot product`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e2917e-9377-4d6e-970b-2e7bdc8e6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w_b(x, w, b):\n",
    "    pred = np.dot(x, w) + b\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65f7cc-6e00-410c-8c7f-5e96fc924802",
   "metadata": {},
   "source": [
    "### cost function for multivariable linear regression\n",
    "The equation for the cost function with multiple variables $J(\\mathbf{w},b)$ is:\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})^2 \\tag{3}$$ \n",
    "where:\n",
    "$$ f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} + b  \\tag{4} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae0803b8-8a7e-447e-87af-55ccbc7555c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_calc(x, y, w, b, f_w_b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(0, m):\n",
    "        pred = f_w_b(x[i], w, b)\n",
    "        #print(pred)\n",
    "        cost += (pred-y[i])**2\n",
    "    cost = (1/(2*m))*cost\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1758285-5941-4859-89aa-c9d362acd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_initial = 500\n",
    "w_initial = np.array([ 0.2, 10, -0.1])\n",
    "\n",
    "x = df.loc[:, df.columns != 'price'].to_numpy()\n",
    "y = df.loc[:, df.columns == 'price'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a686c021-7c2e-4e83-a1db-bb54639db173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204712.41751503])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_calc(x, y, w_init, b_init, f_w_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bddf1-7cf5-40e1-bf1c-05228ff92ab6",
   "metadata": {},
   "source": [
    "### Gradient Descent for Multivariables\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j = w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{5}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ = b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "where, n is the number of features, parameters $w_j$,  $b$, are updated simultaneously and where  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "* m is the number of training examples in the data set\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$ is the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "faa8c902-61cf-49f9-b69d-26c29431c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_calc(x, y, w, b):\n",
    "    m, n = x.shape\n",
    "    \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range (0, m):\n",
    "        diff = f_w_b(x[i], w, b) - y[i]\n",
    "        for j in range(0, n):\n",
    "            dj_dw[j] += diff*x[i, j]\n",
    "        dj_db += diff\n",
    "    \n",
    "    dj_dw = dj_dw/m\n",
    "    dj_db = dj_db/m\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0dad857f-72f5-4cad-b75a-40e4260426ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: [634.51447013]\n",
      "dj_dw at initial w,b: \n",
      " [617993.21258604   1378.42265253  24740.57880531]\n"
     ]
    }
   ],
   "source": [
    "tmp_dj_dw, tmp_dj_db = gradient_calc(x, y, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b31a7d58-3b25-42ac-b476-592e891e9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_calc(x, y, w, b, cost_calc, gradient_calc, alpha, num_iterations):\n",
    "    \n",
    "    costs = []\n",
    "    w_b_s = []\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        dj_dw, dj_db = gradient_calc(x, y, w, b)\n",
    "        \n",
    "        w = w - alpha*dj_dw\n",
    "        b = b - alpha*dj_db\n",
    "        \n",
    "        if i < 100000:\n",
    "            costs.append(cost_calc(x, y, w, b, f_w_b))\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(f'iteration:{i}, cost:{cost_calc(x, y, w, b, f_w_b)}')\n",
    "            \n",
    "    return w, b, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ad27699-a623-48b3-b293-8a94af8eb992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, cost:[42249.96991039]\n",
      "iteration:100, cost:[477.00554879]\n",
      "iteration:200, cost:[476.36190689]\n",
      "iteration:300, cost:[475.72027138]\n",
      "iteration:400, cost:[475.08061194]\n",
      "iteration:500, cost:[474.44292248]\n",
      "iteration:600, cost:[473.80719695]\n",
      "iteration:700, cost:[473.17342928]\n",
      "iteration:800, cost:[472.54161346]\n",
      "iteration:900, cost:[471.91174346]\n",
      "b,w found by gradient descent: [0.00087473],[0.24724536 0.00110022 0.02669521] \n",
      "prediction: [50.25190329], target value: [100]\n",
      "prediction: [248.31624349], target value: [230]\n",
      "prediction: [495.83075586], target value: [500]\n"
     ]
    }
   ],
   "source": [
    "w_input = np.zeros_like(w_initial)\n",
    "b_input = 0.\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 6e-8\n",
    "# run gradient descent \n",
    "w_final, b_final, costs = gradient_descent_calc(x, y, w_input, b_input, cost_calc, gradient_calc, alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final},{w_final} \")\n",
    "m,_ = x.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(x[i], w_final) + b_final}, target value: {y[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
